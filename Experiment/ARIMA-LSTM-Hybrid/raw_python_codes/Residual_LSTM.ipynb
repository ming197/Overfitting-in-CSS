{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600756223865",
   "display_name": "Python 3.6.7 64-bit ('tensorflow': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, Activation\n",
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.regularizers import l1_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "loaded train_X\nloaded dev_X\nloaded test1_X\nloaded test2_X\nloaded train_Y\nloaded dev_Y\nloaded test1_Y\nloaded test2_Y\n"
    }
   ],
   "source": [
    "# Train - Dev - Test Generation\n",
    "train_X= pd.read_csv('../train_dev_test/after_arima/train_X.csv')\n",
    "print('loaded train_X')\n",
    "dev_X = pd.read_csv('../train_dev_test/after_arima/dev_X.csv')\n",
    "print('loaded dev_X')\n",
    "test1_X = pd.read_csv('../train_dev_test/after_arima/test1_X.csv')\n",
    "print('loaded test1_X')\n",
    "test2_X = pd.read_csv('../train_dev_test/after_arima/test2_X.csv')\n",
    "print('loaded test2_X')\n",
    "train_Y = pd.read_csv('../train_dev_test/after_arima/train_Y.csv')\n",
    "print('loaded train_Y')\n",
    "dev_Y = pd.read_csv('../train_dev_test/after_arima/dev_Y.csv')\n",
    "print('loaded dev_Y')\n",
    "test1_Y = pd.read_csv('../train_dev_test/after_arima/test1_Y.csv')\n",
    "print('loaded test1_Y')\n",
    "test2_Y = pd.read_csv('../train_dev_test/after_arima/test2_Y.csv')\n",
    "print('loaded test2_Y')\n",
    "train_X = train_X.loc[:, ~train_X.columns.str.contains('^Unnamed')]\n",
    "dev_X = dev_X.loc[:, ~dev_X.columns.str.contains('^Unnamed')]\n",
    "test1_X = test1_X.loc[:, ~test1_X.columns.str.contains('^Unnamed')]\n",
    "test2_X = test2_X.loc[:, ~test2_X.columns.str.contains('^Unnamed')]\n",
    "train_Y = train_Y.loc[:, ~train_Y.columns.str.contains('^Unnamed')]\n",
    "dev_Y = dev_Y.loc[:, ~dev_Y.columns.str.contains('^Unnamed')]\n",
    "test1_Y = test1_Y.loc[:, ~test1_Y.columns.str.contains('^Unnamed')]\n",
    "test2_Y = test2_Y.loc[:, ~test2_Y.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data sampling\n",
    "STEP = 20\n",
    "#num_list = [STEP*i for i in range(int(1117500/STEP))]\n",
    "\n",
    "_train_X = np.asarray(train_X).reshape((int(1117500/STEP), 20, 1))\n",
    "_dev_X = np.asarray(dev_X).reshape((int(1117500/STEP), 20, 1))\n",
    "_test1_X = np.asarray(test1_X).reshape((int(1117500/STEP), 20, 1))\n",
    "_test2_X = np.asarray(test2_X).reshape((int(1117500/STEP), 20, 1))\n",
    "\n",
    "_train_Y = np.asarray(train_Y).reshape(int(1117500/STEP), 1)\n",
    "_dev_Y = np.asarray(dev_Y).reshape(int(1117500/STEP), 1)\n",
    "_test1_Y = np.asarray(test1_Y).reshape(int(1117500/STEP), 1)\n",
    "_test2_Y = np.asarray(test2_Y).reshape(int(1117500/STEP), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define custom activation\n",
    "class Double_Tanh(Activation):\n",
    "    def __init__(self, activation, **kwargs):\n",
    "        super(Double_Tanh, self).__init__(activation, **kwargs)\n",
    "        self.__name__ = 'double_tanh'\n",
    "\n",
    "def double_tanh(x):\n",
    "    return (K.tanh(x) * 2)\n",
    "\n",
    "get_custom_objects().update({'double_tanh':Double_Tanh(double_tanh)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['loss', 'mean_squared_error', 'mean_absolute_error']\n"
    }
   ],
   "source": [
    "# Model Generation\n",
    "model = Sequential()\n",
    "#check https://machinelearningmastery.com/use-weight-regularization-lstm-networks-time-series-forecasting/\n",
    "model.add(LSTM(25, input_shape=(20,1), dropout=0.0, kernel_regularizer=l1_l2(0.00,0.00), bias_regularizer=l1_l2(0.00,0.00)))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(double_tanh))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse', 'mae'])\n",
    "#, kernel_regularizer=l1_l2(0,0.1), bias_regularizer=l1_l2(0,0.1),\n",
    "\n",
    "print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the Model\n",
    "model_scores = {}\n",
    "Reg = False\n",
    "d = 'hybrid_LSTM'\n",
    "\n",
    "if Reg :\n",
    "    d += '_with_reg'\n",
    "\n",
    "epoch_num=1\n",
    "for _ in range(124):\n",
    "\n",
    "    # train the model\n",
    "    dir = './models/'+d\n",
    "    file_list = os.listdir(dir)\n",
    "    if len(file_list) != 0 :\n",
    "        epoch_num = len(file_list) + 1\n",
    "        recent_model_name = 'epoch'+str(epoch_num-1)+'.h5'\n",
    "        filepath = './models/' + d + '/' + recent_model_name\n",
    "        model = load_model(filepath)\n",
    "\n",
    "    filepath = './models/' + d + '/epoch'+str(epoch_num)+'.h5'\n",
    "\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=False, mode='min')\n",
    "    callbacks_list = [checkpoint]\n",
    "    if len(callbacks_list) == 0:\n",
    "        model.fit(_train_X, _train_Y, epochs=1, batch_size=500, shuffle=True)\n",
    "    else:\n",
    "        model.fit(_train_X, _train_Y, epochs=1, batch_size=500, shuffle=True, callbacks=callbacks_list)\n",
    "\n",
    "    # test the model\n",
    "    score_train = model.evaluate(_train_X, _train_Y)\n",
    "    score_dev = model.evaluate(_dev_X, _dev_Y)\n",
    "    score_test1 = model.evaluate(_test1_X, _test1_Y)\n",
    "    score_test2 = model.evaluate(_test2_X, _test2_Y)\n",
    "\n",
    "    print('train set score : mse - ' + str(score_train[1]) +' / mae - ' + str(score_train[2]))\n",
    "    print('dev set score : mse - ' + str(score_dev[1]) +' / mae - ' + str(score_dev[2]))\n",
    "    print('test1 set score : mse - ' + str(score_test1[1]) +' / mae - ' + str(score_test1[2]))\n",
    "    print('test2 set score : mse - ' + str(score_test2[1]) +' / mae - ' + str(score_test2[2]))\n",
    "#.history['mean_squared_error'][0]\n",
    "    # get former score data\n",
    "    df = pd.read_csv(\"./models/\"+d+\".csv\")\n",
    "    train_mse = list(df['TRAIN_MSE'])\n",
    "    dev_mse = list(df['DEV_MSE'])\n",
    "    test1_mse = list(df['TEST1_MSE'])\n",
    "    test2_mse = list(df['TEST2_MSE'])\n",
    "\n",
    "    train_mae = list(df['TRAIN_MAE'])\n",
    "    dev_mae = list(df['DEV_MAE'])\n",
    "    test1_mae = list(df['TEST1_MAE'])\n",
    "    test2_mae = list(df['TEST2_MAE'])\n",
    "\n",
    "    # append new data\n",
    "    train_mse.append(score_train[1])\n",
    "    dev_mse.append(score_dev[1])\n",
    "    test1_mse.append(score_test1[1])\n",
    "    test2_mse.append(score_test2[1])\n",
    "\n",
    "    train_mae.append(score_train[2])\n",
    "    dev_mae.append(score_dev[2])\n",
    "    test1_mae.append(score_test1[2])\n",
    "    test2_mae.append(score_test2[2])\n",
    "\n",
    "    # organize newly created score dataset\n",
    "    model_scores['TRAIN_MSE'] = train_mse\n",
    "    model_scores['DEV_MSE'] = dev_mse\n",
    "    model_scores['TEST1_MSE'] = test1_mse\n",
    "    model_scores['TEST2_MSE'] = test2_mse\n",
    "\n",
    "    model_scores['TRAIN_MAE'] = train_mae\n",
    "    model_scores['DEV_MAE'] = dev_mae\n",
    "    model_scores['TEST1_MAE'] = test1_mae\n",
    "    model_scores['TEST2_MAE'] = test2_mae\n",
    "\n",
    "    # save newly created score dataset\n",
    "    model_scores_df = pd.DataFrame(model_scores)\n",
    "    model_scores_df.to_csv(\"./models/\"+d+\".csv\")"
   ]
  }
 ]
}