{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../') \n",
    "sys.path.append('../..') \n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sklearn\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "# from viz import viz\n",
    "from bokeh.plotting import figure, show, output_notebook, output_file, save\n",
    "from functions import merge_data\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import load_data\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from fit_and_predict import fit_and_predict\n",
    "from shared_models import SharedModel\n",
    "from collections import defaultdict \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Params:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_by_state = False\n",
    "outcome_type = 'deaths'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded and merged COVID-19 cases/deaths data successfully\n"
     ]
    }
   ],
   "source": [
    "# 'deaths' and 'cases' contain the time-series of the outbreak\n",
    "df = load_data.load_county_level(data_dir = '../data/')\n",
    "# df = df.sort_values('#Deaths_3/30/2020', ascending=False)\n",
    "# outcome_cases = load_data.outcome_cases # most recent day\n",
    "# outcome_deaths = load_data.outcome_deaths\n",
    "important_vars = load_data.important_keys(df)\n",
    "very_important_vars = ['PopulationDensityperSqMile2010',\n",
    "#                        'MedicareEnrollment,AgedTot2017',\n",
    "                       'Respiratory Mortality',\n",
    "                       'PopulationEstimate2018',\n",
    "                       '#ICU_beds',\n",
    "                       'MedianAge2010',\n",
    "                       'Smokers_Percentage',\n",
    "                       'DiabetesPercentage',\n",
    "                       'HeartDiseaseMortality',\n",
    "                        '#Hospitals'\n",
    "#                        'PopMale60-642010',\n",
    "#                         'PopFmle60-642010',\n",
    "#                          'PopMale65-742010',\n",
    "#                          'PopFmle65-742010',\n",
    "#                          'PopMale75-842010',\n",
    "#                          'PopFmle75-842010',\n",
    "#                          'PopMale>842010',\n",
    "#                          'PopFmle>842010'\n",
    "                      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_date = date(2020,1,22)\n",
    "first_ordinal = first_date.toordinal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Create:\n",
    "\n",
    "df['days_since_order'] which is the number of days since the shelter in place order has gone into effect\n",
    "\n",
    "df['week_since_order'] which is if it's been a week since the order\n",
    "\n",
    "df['two_weeks_since_order'] which is if it's been two weeks since the order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "days_since_order = []\n",
    "past_one_week = []\n",
    "past_two_weeks = []\n",
    "shelter_in_place_orders = list(df['stay at home'])\n",
    "nan_counties = []\n",
    "total_num_days = len(list(df['deaths'])[0])\n",
    "for j,order in enumerate(shelter_in_place_orders):\n",
    "    county_days_since_orders = []\n",
    "    county_one_week = []\n",
    "    county_two_week = []\n",
    "    if np.isnan(order):\n",
    "        nan_counties.append(list(df['CountyName'])[j]+ ' '+list(df['StateName'])[j])\n",
    "        order = 1e10\n",
    "    for i in range(total_num_days):\n",
    "        current_date = first_ordinal+i\n",
    "        county_days_since_orders.append(max(current_date-order,0))\n",
    "        county_one_week.append(int(current_date > order + 7))\n",
    "        county_two_week.append(int(current_date > order + 14))\n",
    "\n",
    "    days_since_order.append(county_days_since_orders)\n",
    "    past_one_week.append(county_one_week)\n",
    "    past_two_weeks.append(county_two_week)\n",
    "\n",
    "df['days_since_order'] = days_since_order\n",
    "df['week_since_order'] = past_one_week\n",
    "df['two_weeks_since_order'] = past_two_weeks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find neighboring county deaths/cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighboring_counties_df = pd.read_csv('../data/county_level/raw/county_ids/county_adjacency2010.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['countyFIPS'] = [int(v) for v in list(df['countyFIPS'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_neighbor_deaths = []\n",
    "county_neighbor_cases = []\n",
    "county_fips = list(df['countyFIPS'])\n",
    "number_of_days = len(list(df['deaths'])[0])\n",
    "for fips in county_fips:\n",
    "    neighboring_counties = list(neighboring_counties_df.loc[neighboring_counties_df['fipscounty'] == fips]['fipsneighbor'])\n",
    "    neighboring_county_deaths = list(df.loc[df['countyFIPS'].isin(neighboring_counties)]['deaths'])\n",
    "    neighboring_county_cases = list(df.loc[df['countyFIPS'].isin(neighboring_counties)]['cases'])\n",
    "    \n",
    "\n",
    "    sum_neighboring_county_deaths = np.zeros(number_of_days)\n",
    "    for deaths in neighboring_county_deaths:\n",
    "        sum_neighboring_county_deaths += deaths\n",
    "    sum_neighboring_county_cases = np.zeros(number_of_days)\n",
    "    for cases in neighboring_county_cases:\n",
    "        sum_neighboring_county_cases += cases\n",
    "    county_neighbor_deaths.append(sum_neighboring_county_deaths)\n",
    "    county_neighbor_cases.append(sum_neighboring_county_cases)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['neighbor_deaths'] = county_neighbor_deaths\n",
    "df['neighbor_cases'] = county_neighbor_cases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the number of new deaths (smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_deaths = []\n",
    "deaths = list(df['deaths'])\n",
    "for county_deaths in deaths:\n",
    "    county_new_deaths = []\n",
    "    for i in range(len(list(county_deaths))):\n",
    "        if i == 0: \n",
    "            county_new_deaths.append(list(county_deaths)[0])\n",
    "        else:\n",
    "            county_new_deaths.append(list(county_deaths)[i]-list(county_deaths)[i-1])\n",
    "\n",
    "    smoothed_county_new_deaths = []\n",
    "    window = 5\n",
    "    for i in range(len(county_new_deaths)):\n",
    "        start = max(i-window,0)\n",
    "        end = min(i+window,len(county_new_deaths)-1)\n",
    "        smoothed_county_new_deaths.append(sum(county_new_deaths[start:end])/len(county_new_deaths[start:end]))\n",
    "        \n",
    "    new_deaths.append(np.array(smoothed_county_new_deaths))\n",
    "df['new_deaths'] = new_deaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find number of new deaths per capita * 100k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_deaths = []\n",
    "per_cap_deaths = []\n",
    "deaths = list(df['deaths'])\n",
    "pop = list(df['PopulationEstimate2018'])\n",
    "for county_ind,county_deaths in enumerate(deaths):\n",
    "    county_per_cap_deaths = []\n",
    "    for i in range(len(list(county_deaths))):\n",
    "        county_per_cap_deaths.append(list(county_deaths)[i]/pop[county_ind]*100000)\n",
    "        \n",
    "    per_cap_deaths.append(np.array(county_per_cap_deaths))\n",
    "    \n",
    "df['deaths_per_cap'] = per_cap_deaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find number of new cases per capita * 100k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_deaths = []\n",
    "per_cap_deaths = []\n",
    "deaths = list(df['cases'])\n",
    "pop = list(df['PopulationEstimate2018'])\n",
    "for county_ind,county_deaths in enumerate(deaths):\n",
    "    county_per_cap_deaths = []\n",
    "    for i in range(len(list(county_deaths))):\n",
    "        county_per_cap_deaths.append(list(county_deaths)[i]/pop[county_ind]*100000)\n",
    "        \n",
    "    per_cap_deaths.append(np.array(county_per_cap_deaths))\n",
    "    \n",
    "df['cases_per_cap'] = per_cap_deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_deaths_per_cap = []\n",
    "per_cap_deaths = list(df['deaths_per_cap'])\n",
    "for county_per_cap_deaths in per_cap_deaths:    \n",
    "    max_deaths_per_cap.append( county_per_cap_deaths[-1])\n",
    "    \n",
    "df['max_death_per_cap'] = max_deaths_per_cap\n",
    "\n",
    "per_cap_deaths = list(df['deaths_per_cap'])\n",
    "max_deaths_per_cap = []\n",
    "\n",
    "for county_per_cap_deaths in per_cap_deaths:    \n",
    "    max_deaths_per_cap.append( county_per_cap_deaths[-14])\n",
    "    \n",
    "df['max_death_per_cap_minus_2_weeks'] = max_deaths_per_cap\n",
    "\n",
    "max_deaths_per_cap = []\n",
    "per_cap_deaths = list(df['deaths_per_cap'])\n",
    "for county_per_cap_deaths in per_cap_deaths:    \n",
    "    max_deaths_per_cap.append( county_per_cap_deaths[-14]-county_per_cap_deaths[-19])\n",
    "    \n",
    "df['max_death_per_cap_minus_2_weeks_5_day_growth'] = max_deaths_per_cap\n",
    "\n",
    "\n",
    "max_deaths_per_cap = []\n",
    "per_cap_deaths = list(df['deaths_per_cap'])\n",
    "for county_per_cap_deaths in per_cap_deaths:    \n",
    "    max_deaths_per_cap.append( county_per_cap_deaths[-14]-county_per_cap_deaths[-21])\n",
    "    \n",
    "df['max_death_per_cap_minus_2_weeks_7_day_growth'] = max_deaths_per_cap\n",
    "\n",
    "\n",
    "\n",
    "max_deaths_per_cap = []\n",
    "per_cap_deaths = list(df['deaths_per_cap'])\n",
    "for county_per_cap_deaths in per_cap_deaths:    \n",
    "    max_deaths_per_cap.append( county_per_cap_deaths[-14]-county_per_cap_deaths[-17])\n",
    "    \n",
    "df['max_death_per_cap_minus_2_weeks_3_day_growth'] = max_deaths_per_cap\n",
    "\n",
    "\n",
    "\n",
    "max_deaths = []\n",
    "deaths = list(df['deaths'])\n",
    "for county_deaths in deaths:    \n",
    "    max_deaths.append( county_deaths[-14])\n",
    "    \n",
    "df['max_deaths_minus_two_weeks'] = max_deaths\n",
    "\n",
    "\n",
    "max_deaths = []\n",
    "deaths = list(df['cases'])\n",
    "for county_deaths in deaths:    \n",
    "    max_deaths.append( county_deaths[-14])\n",
    "    \n",
    "df['max_cases_minus_two_weeks'] = max_deaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only include rural counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['Rural-UrbanContinuumCode2013'] > 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df.columns:\n",
    "    if '#' in c:\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features for finding neighbors\n",
    "very_important_vars = [\n",
    "#     'PopulationDensityperSqMile2010',\n",
    "#     'PopulationEstimate2018',\n",
    "#     'Rural-UrbanContinuumCode2013',\n",
    "#      'MedianAge2010',\n",
    "#     'stay at home',\n",
    "#\n",
    "#         '#ICU_beds',\n",
    "\n",
    "    'max_death_per_cap_minus_2_weeks_5_day_growth',\n",
    "      'max_death_per_cap_minus_2_weeks_3_day_growth',\n",
    "          'max_death_per_cap_minus_2_weeks_7_day_growth',\n",
    "#         'max_death_per_cap_minus_2_weeks',\n",
    "#         'max_deaths_minus_two_weeks',\n",
    "#         'max_cases_minus_two_weeks'\n",
    "\n",
    "]\n",
    "\n",
    "# static_features = [ \n",
    "#     'PopulationDensityperSqMile2010',\n",
    "#     'PopulationEstimate2018',\n",
    "#     'Rural-UrbanContinuumCode2013',\n",
    "#      'MedianAge2010',\n",
    "#     'stay at home'\n",
    "# ]\n",
    "# very_important_vars = static_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sort by deaths two weeks ago, scale (and potentially do PCA) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# very_important_vars = static_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import spatial\n",
    "df = df.sort_values('max_deaths_minus_two_weeks', ascending=False)\n",
    "\n",
    "covariates = df[very_important_vars]\n",
    "\n",
    "covariates_clean = covariates.dropna(1)\n",
    "\n",
    "\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n",
    "numeric_covs = covariates_clean.select_dtypes(include=numerics)\n",
    "\n",
    "\n",
    "scaled_covariates = StandardScaler().fit_transform(numeric_covs.values)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "principle_components = pca.fit_transform(scaled_covariates)\n",
    "# principle_components = scaled_covariates\n",
    "tree = spatial.KDTree(principle_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_k_time_dynamic(county_index,time_query,df,num_neighbors,tol=.1):\n",
    "    death_per_cap = list(df['deaths_per_cap'])\n",
    "    print('============')\n",
    "    print(county_index)\n",
    "    print(time_query)\n",
    "    query_val = death_per_cap[county_index][time_query]\n",
    "    possible_indices = []\n",
    "    time_indices = []\n",
    "    for i in range(len(death_per_cap)):\n",
    "\n",
    "        dists = np.abs(death_per_cap[i][:time_query+1]-query_val)\n",
    "        best_match = death_per_cap[i][np.argmin(dists)]\n",
    "        time_index = np.argmin(dists)\n",
    "        if i == county_index:\n",
    "            time_index = len(dists)-1\n",
    "            best_match = death_per_cap[i][time_index]\n",
    "            \n",
    "        assert time_index < len(death_per_cap[i])-time_query, time_index\n",
    "        if best_match < query_val*(1+tol) and best_match > query_val*(1-tol):\n",
    "            possible_indices.append(i)\n",
    "            time_indices.append(time_index)\n",
    "       \n",
    "    index_to_time_dict = {k:v for (k,v) in zip(possible_indices,time_indices)}\n",
    "#     print(list(zip(possible_indices,time_indices)))\n",
    "    most_similar_neighbors, distances = find_top_k_matches(county_index,1500)\n",
    "    \n",
    "    final_matches = []\n",
    "    final_times = []\n",
    "    final_distances = []\n",
    "\n",
    "    for i in range(len(most_similar_neighbors)):\n",
    "        if most_similar_neighbors[i] in possible_indices:\n",
    "            final_matches.append(most_similar_neighbors[i])\n",
    "            final_distances.append(distances[i])\n",
    "            final_times.append(index_to_time_dict[most_similar_neighbors[i]])\n",
    "            if len(final_matches) == num_neighbors:\n",
    "                break\n",
    "\n",
    "    return final_matches, final_times, final_distances\n",
    "            \n",
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds top k nearest neighbors\n",
    "def find_top_k_matches(county_index,num_neighbors):\n",
    "    query_vector = principle_components[county_index]\n",
    "    neighbors = tree.query(query_vector,num_neighbors)\n",
    "    neighbor_indices = list(neighbors[1])\n",
    "    distances = list(neighbors[0])\n",
    "    return neighbor_indices, distances\n",
    "  \n",
    "\n",
    "def find_time_match(query_county_index,match_county_index,query_county_date,outcome='per_cap_deaths'):\n",
    "    query_val = list(df[outcome])[query_county_index][query_county_date]\n",
    "    \n",
    "    dists = np.abs(list(df[outcome])[match_county_index][:query_county_date]-query_val)\n",
    "    time_index = np.argmin(dists)\n",
    "    return time_index\n",
    "\n",
    "    \n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============\n",
      "5\n",
      "-14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([5, 21, 83, 0, 289],\n",
       " [81, 78, 77, 77, 76],\n",
       " [0.0,\n",
       "  0.8821275779065932,\n",
       "  1.5596260447470531,\n",
       "  2.700672245741885,\n",
       "  2.9201579345881217])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_top_k_time_dynamic(5,-14,df,5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Create Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_type = 'deaths_per_cap'\n",
    "import fit_and_predict\n",
    "advanced_model = {'model_type':'advanced_shared_model'}\n",
    "linear = {'model_type':'linear'}\n",
    "d = 14\n",
    "df = fit_and_predict.fit_and_predict_ensemble(df, \n",
    "                                              target_day=np.array(range(1, d+1)),\n",
    "                                              mode='eval_mode',\n",
    "                                              outcome=outcome_type,\n",
    "                                              methods=[ \n",
    "                                                  advanced_model,\n",
    "                                                      linear\n",
    "                                                     ],\n",
    "                                              output_key='predicted_al',\n",
    "                                              verbose=True\n",
    "                                             )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['predicted_al']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_type = 'deaths_per_cap'\n",
    "\n",
    "# outcome_type = 'cases_per_cap'\n",
    "# outcome_type = 'deaths'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_matched_counties(df,indices,time_dif = False, plot_preds = False):\n",
    "#     \"\"\"\n",
    "#     Plots model predictions vs actual\n",
    "#     row: dataframe row\n",
    "#     window: autoregressive window size\n",
    "#     \"\"\"\n",
    "#     outcome = outcome_type\n",
    "    \n",
    "#     if time_dif:\n",
    "#         time_inds = []\n",
    "#         for ind in indices:\n",
    "#             t = find_time_match(indices[0],ind,-14,outcome=outcome)\n",
    "#             time_inds.append(t)\n",
    "    \n",
    "    \n",
    "#     outcomes = list(df[outcome_type])\n",
    "#     counties = list(df['CountyName'])\n",
    "#     states = list(df['StateName'])\n",
    "#     if time_dif:\n",
    "#         print(time_inds)\n",
    "#     for i in range(len(indices)):\n",
    "# #         county_vals = outcomes[indices[i]][times[i]:]\n",
    "#         if time_dif:\n",
    "#             print(len(outcomes[indices[i]][time_inds[i]:]))\n",
    "#             print('-----------------=============-----------')\n",
    "#             county_vals = outcomes[indices[i]][time_inds[i]:]\n",
    "#         else:\n",
    "#             county_vals = outcomes[indices[i]][-14:]\n",
    "#         sns.lineplot(list(range(len(county_vals))),county_vals, label=counties[indices[i]]+' '+states[indices[i]])\n",
    "\n",
    "#     avg_neighbors = np.array(len(ounty_vals = outcomes[indices[0]][time_inds[0]:]))\n",
    "#     for i in range(1,len(indices)):\n",
    "        \n",
    "#         county_vals = outcomes[indices[i]][time_inds[i]:]\n",
    "#         avg_neighbors += county_vals[:len(avg_neighbors)]\n",
    "#     avg_neighbors = avg_neighbors/(len(indices)-1)\n",
    "#     sns.lineplot(list(range(len(avg_neighbors))),avg_neighbors, label='avg neighbor')\n",
    "    \n",
    "\n",
    "        \n",
    "#     if plot_preds:\n",
    "#         preds = list(df['predicted_al'])[indices[0]]\n",
    "\n",
    "#         sns.scatterplot(list(range(len(county_vals)))[-len(preds):],preds,label='pred')\n",
    "\n",
    "#     plt.ylabel(outcome_type)\n",
    "#     plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "#     plt.figure(dpi=500)    \n",
    "#     plt.show()\n",
    "    \n",
    "#     total_difs = 0\n",
    "#     for t in range(1,15):\n",
    "#         vals = []\n",
    "#         for i in range(len(indices)):\n",
    "#             vals.append(outcomes[indices[i]][-t])\n",
    "#         avg_val = np.mean(vals)\n",
    "#         val_difs = np.sum([np.abs(v-avg_val) for v in vals])\n",
    "#         total_difs += val_difs\n",
    "#     pred_difs = 0 \n",
    "    \n",
    "#     if plot_preds:\n",
    "#         for t in range(1,15):\n",
    "#              pred_difs += np.abs(preds[-t] - outcomes[indices[0]][-t])\n",
    "#     if not plot_preds:\n",
    "#         pred_difs = 0\n",
    "#     return total_difs, pred_difs\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dynamic_matched_counties(df,indices,time_dif = False, plot_preds = False, weighted = False):\n",
    "    \"\"\"\n",
    "    Plots model predictions   vs actual\n",
    "    row: dataframe row\n",
    "    window: autoregressive window size\n",
    "    \"\"\"\n",
    "    index = indices[0]\n",
    "    \n",
    "    outcomes = list(df[outcome_type])\n",
    "    counties = list(df['CountyName'])\n",
    "    states = list(df['StateName'])\n",
    "\n",
    "\n",
    "    county_indices, time_indices, distances = find_top_k_time_dynamic(index,-14,df,5,tol=.1)\n",
    "    if len(county_indices) == 1:\n",
    "        print('no match found for county: '+ counties[county_indices[0]])\n",
    "        return None, None\n",
    "    print(len(county_indices))\n",
    "    for i in range(len(county_indices)):\n",
    "\n",
    "        \n",
    "        county_vals = outcomes[county_indices[i]][time_indices[i]:]\n",
    "        if i == 0:\n",
    "            sns.lineplot(list(range(len(county_vals))),county_vals, label=counties[county_indices[i]]+' '+states[county_indices[i]],linewidth=4.0)\n",
    "        else:\n",
    "     \n",
    "            sns.lineplot(list(range(len(county_vals))),county_vals, label=counties[county_indices[i]]+' '+states[county_indices[i]])\n",
    "\n",
    "\n",
    "    avg_neighbors = np.zeros(len(outcomes[county_indices[0]][time_indices[0]:]))\n",
    "    denom = 0\n",
    "    for i in range(1,len(county_indices)):\n",
    "        county_vals = outcomes[county_indices[i]][time_indices[i]:]\n",
    "        if weighted:\n",
    "            avg_neighbors += 1/(distances[i])*county_vals[:len(avg_neighbors)]\n",
    "            denom += 1/(distances[i])\n",
    "        else:\n",
    "            avg_neighbors += county_vals[:len(avg_neighbors)]\n",
    "    \n",
    "    if weighted:\n",
    "        avg_neighbors = avg_neighbors/denom\n",
    "    else:\n",
    "        avg_neighbors = avg_neighbors/(len(county_indices)-1)\n",
    "    \n",
    "    sns.lineplot(list(range(len(avg_neighbors))),avg_neighbors, label='avg neighbor',linewidth=4.0)\n",
    "    \n",
    "\n",
    "    if plot_preds:\n",
    "         \n",
    "        county_vals = outcomes[county_indices[0]][time_indices[0]:]\n",
    "        preds = list(df['predicted_al'])[county_indices[0]]\n",
    "\n",
    "        sns.scatterplot(list(range(len(county_vals)))[-len(preds):],preds,label='pred')\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "    plt.ylabel(outcome_type)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.figure(dpi=500)    \n",
    "    plt.show()\n",
    "    \n",
    "    total_difs = 0\n",
    "    for t in range(1,15):\n",
    "        vals = []\n",
    "        for i in range(len(indices)):\n",
    "            vals.append(outcomes[indices[i]][-t])\n",
    "        avg_val = np.mean(vals)\n",
    "        val_difs = np.sum([np.abs(v-avg_val) for v in vals])\n",
    "        total_difs += val_difs\n",
    "    pred_difs = 0 \n",
    "    \n",
    "    truth = outcomes[county_indices[0]][time_indices[0]:]\n",
    "    avg_diff = 0\n",
    "    for i in range(len(avg_neighbors)):\n",
    "        avg_diff += np.abs(avg_neighbors[i]-truth[i])\n",
    "        \n",
    "        \n",
    "        \n",
    "    if plot_preds:\n",
    "        for t in range(1,15):\n",
    "             pred_difs += np.abs(preds[-t] - outcomes[indices[0]][-t])\n",
    "    if not plot_preds:\n",
    "        pred_difs = 0\n",
    "    total_difs = avg_diff\n",
    "    return total_difs, pred_difs\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_difs = 0\n",
    "pred_difs = 0\n",
    "for i in range(0,20):\n",
    "    neigh_indices = [i] \n",
    "\n",
    "#     val_difs, pred_dif = plot_matched_counties(df,neigh_indices,time_dif=True)\n",
    "    val_difs, pred_dif = plot_dynamic_matched_counties(df,neigh_indices,time_dif=True,plot_preds=True,weighted=False)\n",
    "    \n",
    "    if val_difs is not None:\n",
    "\n",
    "        total_difs += val_difs\n",
    "        pred_difs += pred_dif\n",
    "    \n",
    "print('total dif')\n",
    "print(total_difs)\n",
    "print('pred dif')\n",
    "print(pred_difs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>countyFIPS</th>\n",
       "      <th>STATEFP</th>\n",
       "      <th>COUNTYFP</th>\n",
       "      <th>CountyName</th>\n",
       "      <th>StateName</th>\n",
       "      <th>State</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>POP_LATITUDE</th>\n",
       "      <th>POP_LONGITUDE</th>\n",
       "      <th>...</th>\n",
       "      <th>max_death_per_cap</th>\n",
       "      <th>max_death_per_cap_minus_2_weeks</th>\n",
       "      <th>max_death_per_cap_minus_2_weeks_5_day_growth</th>\n",
       "      <th>max_death_per_cap_minus_2_weeks_7_day_growth</th>\n",
       "      <th>max_death_per_cap_minus_2_weeks_3_day_growth</th>\n",
       "      <th>max_deaths_minus_two_weeks</th>\n",
       "      <th>max_cases_minus_two_weeks</th>\n",
       "      <th>y_preds_0</th>\n",
       "      <th>y_preds_1</th>\n",
       "      <th>predicted_al</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>25011</td>\n",
       "      <td>25.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Franklin</td>\n",
       "      <td>MA</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>42.583106</td>\n",
       "      <td>-72.591410</td>\n",
       "      <td>42.578289</td>\n",
       "      <td>-72.558703</td>\n",
       "      <td>...</td>\n",
       "      <td>45.093922</td>\n",
       "      <td>35.229627</td>\n",
       "      <td>11.273481</td>\n",
       "      <td>18.319406</td>\n",
       "      <td>4.227555</td>\n",
       "      <td>25</td>\n",
       "      <td>143</td>\n",
       "      <td>[31.95256024682155, 31.467412318388707, 30.718...</td>\n",
       "      <td>[33.11584910446288, 33.961360145427896, 34.806...</td>\n",
       "      <td>[32.667899490533046, 33.001011424690965, 33.23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>9005</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Litchfield</td>\n",
       "      <td>CT</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>41.795942</td>\n",
       "      <td>-73.251505</td>\n",
       "      <td>41.727851</td>\n",
       "      <td>-73.187494</td>\n",
       "      <td>...</td>\n",
       "      <td>40.306773</td>\n",
       "      <td>13.251542</td>\n",
       "      <td>8.282214</td>\n",
       "      <td>9.938656</td>\n",
       "      <td>6.073623</td>\n",
       "      <td>24</td>\n",
       "      <td>403</td>\n",
       "      <td>[13.057087123777807, 14.765579106560795, 16.20...</td>\n",
       "      <td>[12.147246716102273, 13.638045176714826, 15.12...</td>\n",
       "      <td>[12.612235347763065, 14.214289598008065, 15.68...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>13205</td>\n",
       "      <td>13.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>GA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>31.212189</td>\n",
       "      <td>-84.213203</td>\n",
       "      <td>31.216853</td>\n",
       "      <td>-84.172094</td>\n",
       "      <td>...</td>\n",
       "      <td>112.653208</td>\n",
       "      <td>63.085797</td>\n",
       "      <td>13.518385</td>\n",
       "      <td>58.579668</td>\n",
       "      <td>4.506128</td>\n",
       "      <td>14</td>\n",
       "      <td>138</td>\n",
       "      <td>[58.79042319482317, 58.69165343969683, 58.6595...</td>\n",
       "      <td>[60.832732516222045, 62.18457101658254, 63.536...</td>\n",
       "      <td>[59.529105999204575, 59.955006705596716, 60.42...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>22097</td>\n",
       "      <td>22.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>St Landry</td>\n",
       "      <td>LA</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>30.603294</td>\n",
       "      <td>-92.003297</td>\n",
       "      <td>30.514029</td>\n",
       "      <td>-92.111314</td>\n",
       "      <td>...</td>\n",
       "      <td>41.080663</td>\n",
       "      <td>15.707312</td>\n",
       "      <td>10.874293</td>\n",
       "      <td>10.874293</td>\n",
       "      <td>10.874293</td>\n",
       "      <td>13</td>\n",
       "      <td>113</td>\n",
       "      <td>[15.672107502495278, 17.96401789207119, 19.822...</td>\n",
       "      <td>[14.499057561258514, 17.278043593833065, 20.05...</td>\n",
       "      <td>[15.164023862145081, 17.66690154059852, 19.924...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>18031</td>\n",
       "      <td>18.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Decatur</td>\n",
       "      <td>IN</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>39.304223</td>\n",
       "      <td>-85.506422</td>\n",
       "      <td>39.319975</td>\n",
       "      <td>-85.494211</td>\n",
       "      <td>...</td>\n",
       "      <td>78.375756</td>\n",
       "      <td>37.321788</td>\n",
       "      <td>14.928715</td>\n",
       "      <td>22.393073</td>\n",
       "      <td>14.928715</td>\n",
       "      <td>10</td>\n",
       "      <td>127</td>\n",
       "      <td>[34.675206135347445, 32.773215829037625, 31.62...</td>\n",
       "      <td>[41.05396730611329, 46.279017690527716, 51.504...</td>\n",
       "      <td>[38.83263602540106, 41.57577526729282, 44.5822...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2290</td>\n",
       "      <td>2.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>Yukon-Koyukuk</td>\n",
       "      <td>AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.010262</td>\n",
       "      <td>-152.550423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.4103536217025587, 3.064161063360857, 4.8606...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.06158985619972761, 0.13381129126848204, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2282</td>\n",
       "      <td>2.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>Yakutat</td>\n",
       "      <td>AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.547975</td>\n",
       "      <td>-139.724878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.6687187821518252, 4.006541344758106, 7.0238...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.03411946357321171, 0.08191975959590019, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2965</th>\n",
       "      <td>53043</td>\n",
       "      <td>53.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>Lincoln</td>\n",
       "      <td>WA</td>\n",
       "      <td>Washington</td>\n",
       "      <td>47.572817</td>\n",
       "      <td>-118.415509</td>\n",
       "      <td>47.633857</td>\n",
       "      <td>-118.325118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[1.4249215405625502, 3.11022810274805, 5.14863...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.07477576100921321, 0.16321577481621177, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1075</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Lamar</td>\n",
       "      <td>AL</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>33.781704</td>\n",
       "      <td>-88.097957</td>\n",
       "      <td>33.762769</td>\n",
       "      <td>-88.109649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>[1.3962831804056337, 3.0145430172000443, 4.760...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.06849863630389702, 0.14788696781239624, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2270</td>\n",
       "      <td>2.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>Wade Hampton</td>\n",
       "      <td>AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.089902</td>\n",
       "      <td>-164.314723</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.6687187821518252, 4.006541344758106, 7.0238...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.03931514875043587, 0.09439443639557765, 0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1975 rows × 295 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      countyFIPS  STATEFP  COUNTYFP     CountyName StateName          State  \\\n",
       "1214       25011     25.0      11.0       Franklin        MA  Massachusetts   \n",
       "304         9005      9.0       5.0     Litchfield        CT    Connecticut   \n",
       "480        13205     13.0     205.0       Mitchell        GA        Georgia   \n",
       "1153       22097     22.0      97.0      St Landry        LA      Louisiana   \n",
       "704        18031     18.0      31.0        Decatur        IN        Indiana   \n",
       "...          ...      ...       ...            ...       ...            ...   \n",
       "90          2290      2.0     290.0  Yukon-Koyukuk        AK            NaN   \n",
       "89          2282      2.0     282.0        Yakutat        AK            NaN   \n",
       "2965       53043     53.0      43.0        Lincoln        WA     Washington   \n",
       "37          1075      1.0      75.0          Lamar        AL        Alabama   \n",
       "88          2270      2.0     270.0   Wade Hampton        AK            NaN   \n",
       "\n",
       "            lat         lon  POP_LATITUDE  POP_LONGITUDE  ...  \\\n",
       "1214  42.583106  -72.591410     42.578289     -72.558703  ...   \n",
       "304   41.795942  -73.251505     41.727851     -73.187494  ...   \n",
       "480   31.212189  -84.213203     31.216853     -84.172094  ...   \n",
       "1153  30.603294  -92.003297     30.514029     -92.111314  ...   \n",
       "704   39.304223  -85.506422     39.319975     -85.494211  ...   \n",
       "...         ...         ...           ...            ...  ...   \n",
       "90          NaN         NaN     65.010262    -152.550423  ...   \n",
       "89          NaN         NaN     59.547975    -139.724878  ...   \n",
       "2965  47.572817 -118.415509     47.633857    -118.325118  ...   \n",
       "37    33.781704  -88.097957     33.762769     -88.109649  ...   \n",
       "88          NaN         NaN     62.089902    -164.314723  ...   \n",
       "\n",
       "     max_death_per_cap max_death_per_cap_minus_2_weeks  \\\n",
       "1214         45.093922                       35.229627   \n",
       "304          40.306773                       13.251542   \n",
       "480         112.653208                       63.085797   \n",
       "1153         41.080663                       15.707312   \n",
       "704          78.375756                       37.321788   \n",
       "...                ...                             ...   \n",
       "90            0.000000                        0.000000   \n",
       "89            0.000000                        0.000000   \n",
       "2965          0.000000                        0.000000   \n",
       "37            0.000000                        0.000000   \n",
       "88            0.000000                        0.000000   \n",
       "\n",
       "      max_death_per_cap_minus_2_weeks_5_day_growth  \\\n",
       "1214                                     11.273481   \n",
       "304                                       8.282214   \n",
       "480                                      13.518385   \n",
       "1153                                     10.874293   \n",
       "704                                      14.928715   \n",
       "...                                            ...   \n",
       "90                                        0.000000   \n",
       "89                                        0.000000   \n",
       "2965                                      0.000000   \n",
       "37                                        0.000000   \n",
       "88                                        0.000000   \n",
       "\n",
       "      max_death_per_cap_minus_2_weeks_7_day_growth  \\\n",
       "1214                                     18.319406   \n",
       "304                                       9.938656   \n",
       "480                                      58.579668   \n",
       "1153                                     10.874293   \n",
       "704                                      22.393073   \n",
       "...                                            ...   \n",
       "90                                        0.000000   \n",
       "89                                        0.000000   \n",
       "2965                                      0.000000   \n",
       "37                                        0.000000   \n",
       "88                                        0.000000   \n",
       "\n",
       "      max_death_per_cap_minus_2_weeks_3_day_growth  \\\n",
       "1214                                      4.227555   \n",
       "304                                       6.073623   \n",
       "480                                       4.506128   \n",
       "1153                                     10.874293   \n",
       "704                                      14.928715   \n",
       "...                                            ...   \n",
       "90                                        0.000000   \n",
       "89                                        0.000000   \n",
       "2965                                      0.000000   \n",
       "37                                        0.000000   \n",
       "88                                        0.000000   \n",
       "\n",
       "      max_deaths_minus_two_weeks  max_cases_minus_two_weeks  \\\n",
       "1214                          25                        143   \n",
       "304                           24                        403   \n",
       "480                           14                        138   \n",
       "1153                          13                        113   \n",
       "704                           10                        127   \n",
       "...                          ...                        ...   \n",
       "90                             0                          1   \n",
       "89                             0                          0   \n",
       "2965                           0                          2   \n",
       "37                             0                          8   \n",
       "88                             0                          0   \n",
       "\n",
       "                                              y_preds_0  \\\n",
       "1214  [31.95256024682155, 31.467412318388707, 30.718...   \n",
       "304   [13.057087123777807, 14.765579106560795, 16.20...   \n",
       "480   [58.79042319482317, 58.69165343969683, 58.6595...   \n",
       "1153  [15.672107502495278, 17.96401789207119, 19.822...   \n",
       "704   [34.675206135347445, 32.773215829037625, 31.62...   \n",
       "...                                                 ...   \n",
       "90    [1.4103536217025587, 3.064161063360857, 4.8606...   \n",
       "89    [1.6687187821518252, 4.006541344758106, 7.0238...   \n",
       "2965  [1.4249215405625502, 3.11022810274805, 5.14863...   \n",
       "37    [1.3962831804056337, 3.0145430172000443, 4.760...   \n",
       "88    [1.6687187821518252, 4.006541344758106, 7.0238...   \n",
       "\n",
       "                                              y_preds_1  \\\n",
       "1214  [33.11584910446288, 33.961360145427896, 34.806...   \n",
       "304   [12.147246716102273, 13.638045176714826, 15.12...   \n",
       "480   [60.832732516222045, 62.18457101658254, 63.536...   \n",
       "1153  [14.499057561258514, 17.278043593833065, 20.05...   \n",
       "704   [41.05396730611329, 46.279017690527716, 51.504...   \n",
       "...                                                 ...   \n",
       "90    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "89    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2965  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "37    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "88    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                           predicted_al  \n",
       "1214  [32.667899490533046, 33.001011424690965, 33.23...  \n",
       "304   [12.612235347763065, 14.214289598008065, 15.68...  \n",
       "480   [59.529105999204575, 59.955006705596716, 60.42...  \n",
       "1153  [15.164023862145081, 17.66690154059852, 19.924...  \n",
       "704   [38.83263602540106, 41.57577526729282, 44.5822...  \n",
       "...                                                 ...  \n",
       "90    [0.06158985619972761, 0.13381129126848204, 0.2...  \n",
       "89    [0.03411946357321171, 0.08191975959590019, 0.1...  \n",
       "2965  [0.07477576100921321, 0.16321577481621177, 0.2...  \n",
       "37    [0.06849863630389702, 0.14788696781239624, 0.2...  \n",
       "88    [0.03931514875043587, 0.09439443639557765, 0.1...  \n",
       "\n",
       "[1975 rows x 295 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1975"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rural_codes = list(df['Rural-UrbanContinuumCode2013'])\n",
    "deaths = list(df['deaths'])\n",
    "rural_counties = Counter({i:deaths[i][-14] for i in range(len(df)) if rural_codes[i] > 3})\n",
    "rural_counties = [r[0] for r in rural_counties.most_common()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in rural_counties:\n",
    "    print(df.iloc[r]['deaths'][-14])\n",
    "    print(deaths[r][-14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_difs = 0\n",
    "pred_difs = 0\n",
    "for i in rural_counties[:20]:\n",
    "    neigh_indices = find_top_k_matches(i,5)\n",
    "    neigh_indices = [i] \n",
    "\n",
    "#     val_difs, pred_dif = plot_matched_counties(df,neigh_indices,time_dif=True)\n",
    "    val_difs, pred_dif = plot_dynamic_matched_counties(df,neigh_indices,time_dif=True,plot_preds=True,weighted=False)\n",
    "\n",
    "    if val_difs:\n",
    "        total_difs += val_difs\n",
    "        pred_difs += pred_dif\n",
    "    \n",
    "print('total dif')\n",
    "print(total_difs)\n",
    "print('pred dif')\n",
    "print(pred_difs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big one: 26508.589044247\n",
    "extra feats: 17280.911096252134\n",
    "statics: 29542.312627359406\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-35-1b65b7d2966e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-35-1b65b7d2966e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    counties 0-20\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "counties 0-20\n",
    "cases total_dif  24518.308526995912\n",
    "deaths total_dif 22761.696791437957\n",
    "features total_dif 11958.136102136708\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rural_features = 10391.618997903128\n",
    "no features = 19653.958291458024\n",
    "static_features = 11142.3903320078\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
