{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../') \n",
    "sys.path.append('../..') \n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sklearn\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "# from viz import viz\n",
    "from bokeh.plotting import figure, show, output_notebook, output_file, save\n",
    "from functions import merge_data\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import load_data\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from fit_and_predict import fit_and_predict\n",
    "from shared_models import SharedModel\n",
    "from collections import defaultdict \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Params:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_by_state = False\n",
    "outcome_type = 'deaths'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded and merged COVID-19 cases/deaths data successfully\n"
     ]
    }
   ],
   "source": [
    "# 'deaths' and 'cases' contain the time-series of the outbreak\n",
    "df = load_data.load_county_level(data_dir = '../data/')\n",
    "important_vars = load_data.important_keys(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_date = date(2020,1,22)\n",
    "first_ordinal = first_date.toordinal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Create:\n",
    "\n",
    "df['days_since_order'] which is the number of days since the shelter in place order has gone into effect\n",
    "\n",
    "df['week_since_order'] which is if it's been a week since the order\n",
    "\n",
    "df['two_weeks_since_order'] which is if it's been two weeks since the order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "days_since_order = []\n",
    "past_one_week = []\n",
    "past_two_weeks = []\n",
    "shelter_in_place_orders = list(df['stay at home'])\n",
    "nan_counties = []\n",
    "total_num_days = len(list(df['deaths'])[0])\n",
    "for j,order in enumerate(shelter_in_place_orders):\n",
    "    county_days_since_orders = []\n",
    "    county_one_week = []\n",
    "    county_two_week = []\n",
    "    if np.isnan(order):\n",
    "        nan_counties.append(list(df['CountyName'])[j]+ ' '+list(df['StateName'])[j])\n",
    "        order = 1e10\n",
    "    for i in range(total_num_days):\n",
    "        current_date = first_ordinal+i\n",
    "        county_days_since_orders.append(max(current_date-order,0))\n",
    "        county_one_week.append(int(current_date > order + 7))\n",
    "        county_two_week.append(int(current_date > order + 14))\n",
    "\n",
    "    days_since_order.append(county_days_since_orders)\n",
    "    past_one_week.append(county_one_week)\n",
    "    past_two_weeks.append(county_two_week)\n",
    "\n",
    "df['days_since_order'] = days_since_order\n",
    "df['week_since_order'] = past_one_week\n",
    "df['two_weeks_since_order'] = past_two_weeks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find neighboring county deaths/cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighboring_counties_df = pd.read_csv('../data/county_level/raw/county_ids/county_adjacency2010.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['countyFIPS'] = [int(v) for v in list(df['countyFIPS'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_neighbor_deaths = []\n",
    "county_neighbor_cases = []\n",
    "county_fips = list(df['countyFIPS'])\n",
    "number_of_days = len(list(df['deaths'])[0])\n",
    "for fips in county_fips:\n",
    "    neighboring_counties = list(neighboring_counties_df.loc[neighboring_counties_df['fipscounty'] == fips]['fipsneighbor'])\n",
    "    neighboring_county_deaths = list(df.loc[df['countyFIPS'].isin(neighboring_counties)]['deaths'])\n",
    "    neighboring_county_cases = list(df.loc[df['countyFIPS'].isin(neighboring_counties)]['cases'])\n",
    "    \n",
    "\n",
    "    sum_neighboring_county_deaths = np.zeros(number_of_days)\n",
    "    for deaths in neighboring_county_deaths:\n",
    "        sum_neighboring_county_deaths += deaths\n",
    "    sum_neighboring_county_cases = np.zeros(number_of_days)\n",
    "    for cases in neighboring_county_cases:\n",
    "        sum_neighboring_county_cases += cases\n",
    "    county_neighbor_deaths.append(sum_neighboring_county_deaths)\n",
    "    county_neighbor_cases.append(sum_neighboring_county_cases)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['neighbor_deaths'] = county_neighbor_deaths\n",
    "df['neighbor_cases'] = county_neighbor_cases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the number of new deaths (smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_deaths = []\n",
    "deaths = list(df['deaths'])\n",
    "for county_deaths in deaths:\n",
    "    county_new_deaths = []\n",
    "    for i in range(len(list(county_deaths))):\n",
    "        if i == 0: \n",
    "            county_new_deaths.append(list(county_deaths)[0])\n",
    "        else:\n",
    "            county_new_deaths.append(list(county_deaths)[i]-list(county_deaths)[i-1])\n",
    "\n",
    "    smoothed_county_new_deaths = []\n",
    "    window = 5\n",
    "    for i in range(len(county_new_deaths)):\n",
    "        start = max(i-window,0)\n",
    "        end = min(i+window,len(county_new_deaths)-1)\n",
    "        smoothed_county_new_deaths.append(sum(county_new_deaths[start:end])/len(county_new_deaths[start:end]))\n",
    "        \n",
    "    new_deaths.append(np.array(smoothed_county_new_deaths))\n",
    "df['new_deaths'] = new_deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_day_growth(k):\n",
    "    new_deaths = []\n",
    "    deaths = list(df['deaths'])\n",
    "    for county_deaths in deaths:\n",
    "        county_new_deaths = []\n",
    "        for i in range(len(list(county_deaths))):\n",
    "            if i < k: \n",
    "                county_new_deaths.append(list(county_deaths)[0])\n",
    "            else:\n",
    "                county_new_deaths.append(list(county_deaths)[i]-list(county_deaths)[i-k])\n",
    "\n",
    "        new_deaths.append(county_new_deaths)\n",
    "    df['deaths_'+str(k)+'_day_growth'] = new_deaths\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_day_growth(3)\n",
    "k_day_growth(5)\n",
    "k_day_growth(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find number of new deaths per capita * 100k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_deaths = []\n",
    "per_cap_deaths = []\n",
    "deaths = list(df['deaths'])\n",
    "pop = list(df['PopulationEstimate2018'])\n",
    "for county_ind,county_deaths in enumerate(deaths):\n",
    "    county_per_cap_deaths = []\n",
    "    for i in range(len(list(county_deaths))):\n",
    "        county_per_cap_deaths.append(list(county_deaths)[i]/pop[county_ind]*100000)\n",
    "        \n",
    "    per_cap_deaths.append(np.array(county_per_cap_deaths))\n",
    "    \n",
    "df['deaths_per_cap'] = per_cap_deaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find number of new cases per capita * 100k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_deaths = []\n",
    "per_cap_deaths = []\n",
    "deaths = list(df['cases'])\n",
    "pop = list(df['PopulationEstimate2018'])\n",
    "for county_ind,county_deaths in enumerate(deaths):\n",
    "    county_per_cap_deaths = []\n",
    "    for i in range(len(list(county_deaths))):\n",
    "        county_per_cap_deaths.append(list(county_deaths)[i]/pop[county_ind]*100000)\n",
    "        \n",
    "    per_cap_deaths.append(np.array(county_per_cap_deaths))\n",
    "    \n",
    "df['cases_per_cap'] = per_cap_deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_deaths_per_cap = []\n",
    "per_cap_deaths = list(df['deaths_per_cap'])\n",
    "for county_per_cap_deaths in per_cap_deaths:    \n",
    "    max_deaths_per_cap.append( county_per_cap_deaths[-1])\n",
    "    \n",
    "df['max_death_per_cap'] = max_deaths_per_cap\n",
    "\n",
    "per_cap_deaths = list(df['deaths_per_cap'])\n",
    "max_deaths_per_cap = []\n",
    "\n",
    "for county_per_cap_deaths in per_cap_deaths:    \n",
    "    max_deaths_per_cap.append( county_per_cap_deaths[-14])\n",
    "    \n",
    "df['max_death_per_cap_minus_2_weeks'] = max_deaths_per_cap\n",
    "\n",
    "max_deaths_per_cap = []\n",
    "per_cap_deaths = list(df['deaths_per_cap'])\n",
    "for county_per_cap_deaths in per_cap_deaths:    \n",
    "    max_deaths_per_cap.append( county_per_cap_deaths[-14]-county_per_cap_deaths[-19])\n",
    "    \n",
    "df['max_death_per_cap_minus_2_weeks_5_day_growth'] = max_deaths_per_cap\n",
    "\n",
    "\n",
    "max_deaths_per_cap = []\n",
    "per_cap_deaths = list(df['deaths_per_cap'])\n",
    "for county_per_cap_deaths in per_cap_deaths:    \n",
    "    max_deaths_per_cap.append( county_per_cap_deaths[-14]-county_per_cap_deaths[-21])\n",
    "    \n",
    "df['max_death_per_cap_minus_2_weeks_7_day_growth'] = max_deaths_per_cap\n",
    "\n",
    "\n",
    "\n",
    "max_deaths_per_cap = []\n",
    "per_cap_deaths = list(df['deaths_per_cap'])\n",
    "for county_per_cap_deaths in per_cap_deaths:    \n",
    "    max_deaths_per_cap.append( county_per_cap_deaths[-14]-county_per_cap_deaths[-17])\n",
    "    \n",
    "df['max_death_per_cap_minus_2_weeks_3_day_growth'] = max_deaths_per_cap\n",
    "\n",
    "\n",
    "\n",
    "max_deaths = []\n",
    "deaths = list(df['deaths'])\n",
    "for county_deaths in deaths:    \n",
    "    max_deaths.append( county_deaths[-14])\n",
    "    \n",
    "df['max_deaths_minus_two_weeks'] = max_deaths\n",
    "\n",
    "\n",
    "max_deaths = []\n",
    "deaths = list(df['cases'])\n",
    "for county_deaths in deaths:    \n",
    "    max_deaths.append( county_deaths[-14])\n",
    "    \n",
    "df['max_cases_minus_two_weeks'] = max_deaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only include rural counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['Rural-UrbanContinuumCode2013'] > 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features for finding neighbors\n",
    "very_important_vars = [\n",
    "#     'PopulationDensityperSqMile2010',\n",
    "#     'PopulationEstimate2018',\n",
    "#     'Rural-UrbanContinuumCode2013',\n",
    "#      'MedianAge2010',\n",
    "#     'stay at home',\n",
    "#\n",
    "#         '#ICU_beds',\n",
    "\n",
    "    'max_death_per_cap_minus_2_weeks_5_day_growth',\n",
    "      'max_death_per_cap_minus_2_weeks_3_day_growth',\n",
    "          'max_death_per_cap_minus_2_weeks_7_day_growth',\n",
    "#         'max_death_per_cap_minus_2_weeks',\n",
    "#         'max_deaths_minus_two_weeks',\n",
    "#         'max_cases_minus_two_weeks'\n",
    "\n",
    "]\n",
    "\n",
    "static_features = [ \n",
    "    'PopulationDensityperSqMile2010',\n",
    "    'PopulationEstimate2018',\n",
    "    'Rural-UrbanContinuumCode2013',\n",
    "     'MedianAge2010',\n",
    "#     'stay at home'\n",
    "]\n",
    "very_important_vars = static_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "very_important_vars = [\n",
    "#     'PopulationDensityperSqMile2010',\n",
    "#     'PopulationEstimate2018',\n",
    "#     'Rural-UrbanContinuumCode2013',\n",
    "#      'MedianAge2010',\n",
    "#     'stay at home',\n",
    "#\n",
    "#         '#ICU_beds',\n",
    "\n",
    "    'max_death_per_cap_minus_2_weeks_5_day_growth',\n",
    "      'max_death_per_cap_minus_2_weeks_3_day_growth',\n",
    "          'max_death_per_cap_minus_2_weeks_7_day_growth',\n",
    "#         'max_death_per_cap_minus_2_weeks',\n",
    "#         'max_deaths_minus_two_weeks',\n",
    "#         'max_cases_minus_two_weeks'\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "1214    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "480     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "1153    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "508     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "                              ...                        \n",
       "11      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "9       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "6       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "5       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "2       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "Name: deaths_per_cap, Length: 1975, dtype: object"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['deaths_per_cap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_features=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_features = ['deaths_per_cap','deaths','new_deaths','deaths_3_day_growth','deaths_5_day_growth','deaths_7_day_growth']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "sort by deaths two weeks ago, scale (and potentially do PCA) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import spatial\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# df = df.sort_values(['max_death_per_cap_minus_2_weeks','countyFIPS'], ascending=False)\n",
    "df = df.sort_values(['max_deaths_minus_two_weeks','countyFIPS'], ascending=False)\n",
    "\n",
    "\n",
    "covariates = df[very_important_vars]\n",
    "\n",
    "covariates_clean = covariates.dropna(1)\n",
    " \n",
    "\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n",
    "numeric_covs = covariates_clean.select_dtypes(include=numerics)\n",
    "\n",
    "\n",
    "scaled_covariates = StandardScaler().fit_transform(numeric_covs.values)\n",
    "\n",
    "pca = PCA(n_components=max(1,int(len(very_important_vars)/3)))\n",
    "principle_components = pca.fit_transform(scaled_covariates)\n",
    "# principle_components = scaled_covariates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(static_features,dynamic_features,time_index):\n",
    "    static_covariates = df[static_features].values\n",
    "    all_dynamic_covariates = df[dynamic_features].values\n",
    "    dynamic_covariates_unprocessed = list(df[dynamic_features].values)\n",
    "    dynamic_covariates = []\n",
    "    for county in dynamic_covariates_unprocessed:\n",
    "        county_proc = []\n",
    "        for feature in list(county):\n",
    "            county_proc.append(list(feature))\n",
    "        dynamic_covariates.append(county_proc)\n",
    "        \n",
    "    dynamic_covariates = np.array(dynamic_covariates)[:,:,time_index]\n",
    "        \n",
    "    covariates = np.concatenate([static_covariates,dynamic_covariates],axis=1)\n",
    "    scaler = StandardScaler()\n",
    "    scaled_covariates = scaler.fit_transform(covariates)\n",
    "    pca = PCA(n_components=max(1,int(scaled_covariates.shape[1]/3)))\n",
    "    principle_components = pca.fit_transform(scaled_covariates)\n",
    "    return principle_components, scaler, pca\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_k_time_dynamic(county_index,time_query,df,num_neighbors,tol=.1):\n",
    "    death_per_cap = list(df['deaths_per_cap'])\n",
    "    query_val = death_per_cap[county_index][time_query]\n",
    "    possible_indices = []\n",
    "    time_indices = []\n",
    "    query_dists = []\n",
    "    for i in range(len(death_per_cap)):\n",
    "        if i != county_index:\n",
    "            dists = np.abs(death_per_cap[i][:time_query-14+1]-query_val)\n",
    "            best_match = death_per_cap[i][np.argmin(dists)]\n",
    "            time_index = np.argmin(dists)\n",
    "            assert time_index < len(death_per_cap[i])-time_query, time_index\n",
    "            if best_match < query_val*(1+tol) and best_match > query_val*(1-tol):\n",
    "                possible_indices.append(i)\n",
    "                time_indices.append(time_index)\n",
    "                query_dists.append(np.abs(best_match-query_val))\n",
    "    index_to_time_dict = {k:v for (k,v) in zip(possible_indices,time_indices)}\n",
    "    \n",
    "    \n",
    "    neighbor_features, scaler, pca = generate_features(static_features,dynamic_features,time_query-14)\n",
    "    county_static_features = df.iloc[county_index][static_features]\n",
    "    county_dynamic_featurees = np.vstack(list(df.iloc[county_index][dynamic_features]))[:,time_query]\n",
    "    county_features = np.concatenate([county_static_features,county_dynamic_featurees])\n",
    "    transformed_county_features = pca.transform(scaler.transform(county_features.reshape(1, -1)))\n",
    "    \n",
    "    most_similar_neighbors, distances = find_top_k_matches(transformed_county_features[0],neighbor_features,\n",
    "                                                          len(df)) \n",
    "\n",
    "\n",
    "    final_matches = []\n",
    "    final_times = []\n",
    "    final_distances = []\n",
    "\n",
    "    for i in range(len(most_similar_neighbors)):\n",
    "        if most_similar_neighbors[i] in possible_indices:\n",
    "            final_matches.append(most_similar_neighbors[i])\n",
    "            final_distances.append(distances[i])\n",
    "            final_times.append(index_to_time_dict[most_similar_neighbors[i]])\n",
    "            if len(final_matches) == num_neighbors:\n",
    "                break\n",
    "    final_matches = [county_index] + final_matches\n",
    "    final_times = [len(dists)-1] + final_times\n",
    "    final_distances = [0] + final_distances\n",
    "\n",
    "    return final_matches, final_times, final_distances\n",
    "            \n",
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_type = 'deaths_per_cap'\n",
    "\n",
    "# outcome_type = 'cases_per_cap'\n",
    "# outcome_type = 'deaths'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outcome_type = 'deaths'\n",
    "import fit_and_predict\n",
    "advanced_model = {'model_type':'advanced_shared_model'}\n",
    "linear = {'model_type':'linear'}\n",
    "d = 14\n",
    "df = fit_and_predict.fit_and_predict_ensemble(df, \n",
    "                                              target_day=np.array(range(1, d+1)),\n",
    "                                              mode='eval_mode',\n",
    "                                              outcome=outcome_type,\n",
    "                                              methods=[ \n",
    "                                                  advanced_model,\n",
    "                                                      linear\n",
    "                                                     ],\n",
    "                                              output_key='predicted_al',\n",
    "                                              verbose=True\n",
    "                                             )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['predicted_al']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_type = 'deaths_per_cap'\n",
    "\n",
    "# outcome_type = 'cases_per_cap'\n",
    "# outcome_type = 'deaths'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dynamic_matched_counties(df,indices,time_dif = False, plot_preds = False, weighted = False):\n",
    "    \"\"\"\n",
    "    Plots model predictions   vs actual\n",
    "    row: dataframe row\n",
    "    window: autoregressive window size\n",
    "    \"\"\"\n",
    "    index = indices[0]\n",
    "    \n",
    "    outcomes = list(df[outcome_type])\n",
    "    counties = list(df['CountyName'])\n",
    "    states = list(df['StateName'])\n",
    "\n",
    "\n",
    "    county_indices, time_indices, distances = find_top_k_time_dynamic(index,-14,df,5,tol=.1)\n",
    "    if len(county_indices) == 1:\n",
    "        print('no match found for county: '+ counties[county_indices[0]])\n",
    "        return None, None\n",
    "\n",
    "    for i in range(len(county_indices)):\n",
    "\n",
    "        \n",
    "        county_vals = outcomes[county_indices[i]][time_indices[i]:]\n",
    "        if i == 0:\n",
    "            county_vals = outcomes[county_indices[i]][time_indices[i]:]\n",
    "\n",
    "            sns.lineplot(list(range(len(county_vals))),county_vals, label=counties[county_indices[i]]+' '+states[county_indices[i]],linewidth=4.0)\n",
    "        else:\n",
    "            county_vals = outcomes[county_indices[i]][time_indices[i]-14:]\n",
    "\n",
    "     \n",
    "            sns.lineplot(list(range(len(county_vals))),county_vals, label=counties[county_indices[i]]+' '+states[county_indices[i]])\n",
    "\n",
    "\n",
    "#     avg_neighbors = np.zeros(len(outcomes[county_indices[0]][time_indices[0]-14:]))\n",
    "    avg_neighbors = np.zeros(28)\n",
    "\n",
    "    denom = 0\n",
    "    for i in range(1,len(county_indices)):\n",
    "        county_vals = outcomes[county_indices[i]][time_indices[i]-14:]\n",
    "        if weighted:\n",
    "            avg_neighbors += 1/(distances[i])*county_vals[:len(avg_neighbors)]\n",
    "            denom += 1/(distances[i])\n",
    "        else:\n",
    "            avg_neighbors += county_vals[:len(avg_neighbors)]\n",
    "    \n",
    "    if weighted:\n",
    "        avg_neighbors = avg_neighbors/denom\n",
    "    else:\n",
    "        avg_neighbors = avg_neighbors/(len(county_indices)-1)\n",
    "    \n",
    "    sns.lineplot(list(range(len(avg_neighbors))),avg_neighbors, label='avg neighbor',linewidth=4.0)\n",
    "    \n",
    "\n",
    "    if plot_preds:\n",
    "         \n",
    "        county_vals = outcomes[county_indices[0]][time_indices[0]:]\n",
    "        preds = list(df['predicted_al'])[county_indices[0]]\n",
    "\n",
    "        sns.scatterplot(list(range(len(county_vals)))[-len(preds):],preds,label='pred')\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "    plt.ylabel(outcome_type)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.figure(dpi=500)    \n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    \n",
    "    truth = outcomes[county_indices[0]][time_indices[0]:]\n",
    "    avg_diff = 0\n",
    "    for i in range(len(avg_neighbors)-14):\n",
    "        avg_diff += np.abs(avg_neighbors[-i]-truth[-i])\n",
    "        \n",
    "    pred_difs = 0\n",
    "        \n",
    "    if plot_preds:\n",
    "        for t in range(1,15):\n",
    "             pred_difs += np.abs(preds[-t] - outcomes[indices[0]][-t])\n",
    "    if not plot_preds:\n",
    "        pred_difs = 0\n",
    "    total_difs = avg_diff\n",
    "    return total_difs, pred_difs\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_difs = 0\n",
    "pred_difs = 0\n",
    "for i in range(0,80):\n",
    "    neigh_indices = [i] \n",
    "\n",
    "#     val_difs, pred_dif = plot_matched_counties(df,neigh_indices,time_dif=True)\n",
    "    val_difs, pred_dif = plot_dynamic_matched_counties(df,neigh_indices,time_dif=True,plot_preds=True,weighted=True)\n",
    "    \n",
    "    if val_difs is not None:\n",
    "\n",
    "        total_difs += val_difs\n",
    "        pred_difs += pred_dif\n",
    "    \n",
    "print('total dif')\n",
    "print(total_difs)\n",
    "print('pred dif')\n",
    "print(pred_difs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rural_codes = list(df['Rural-UrbanContinuumCode2013'])\n",
    "deaths = list(df['deaths'])\n",
    "rural_counties = Counter({i:deaths[i][-14] for i in range(len(df)) if rural_codes[i] > 3})\n",
    "rural_counties = [r[0] for r in rural_counties.most_common()]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
