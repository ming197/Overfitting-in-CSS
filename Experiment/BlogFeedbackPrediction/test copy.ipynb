{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.6 64-bit ('base': conda)",
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "df619985315deac7a16192b1002f6732827f3aaa3582dc671808acaae285e381"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import ShuffleSplit, train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "import math, os, random \n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score, make_scorer, mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the learning curve\n",
    "def plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "  \n",
    "    if axes is None:\n",
    "        _, axes = plt.subplots(1, 1, figsize=(20, 5), squeeze=False)\n",
    "\n",
    "    axes[0].set_title(title)\n",
    "    if ylim is not None:\n",
    "        axes[0].set_ylim(*ylim)\n",
    "    axes[0].set_xlabel(\"Training examples\")\n",
    "    axes[0].set_ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores, fit_times, _ = \\\n",
    "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
    "                       train_sizes=train_sizes,\n",
    "                       return_times=True, scoring=make_scorer(r2_score))\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    fit_times_mean = np.mean(fit_times, axis=1)\n",
    "    fit_times_std = np.std(fit_times, axis=1)\n",
    "    print(\"the shape of train_scores_mean\", train_scores_mean.shape)\n",
    "    print(train_scores_mean)\n",
    "    print(\"the shape of test_scores_mean\", test_scores_mean.shape)\n",
    "    print(test_scores_mean)\n",
    "    \n",
    "    axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                 label=\"Training r2_score\")\n",
    "    axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "                 label=\"Testing r2_score\")\n",
    "    axes[0].legend(loc=\"best\")\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=0.2, use_cuda=False):\n",
    "\n",
    "    # pandas DataFrame to numpy array\n",
    "    x = x.values\n",
    "    y = y.values\n",
    "\n",
    "    '''Compute the mixup data. Return mixed inputs, pairs of targets, and lambda'''\n",
    "    if alpha > 0.:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1.\n",
    "\n",
    "    train_size = x.shape[0]\n",
    "    if use_cuda:\n",
    "        # index = torch.randperm(batch_size).cuda()\n",
    "        pass\n",
    "    else:\n",
    "        index = np.random.permutation(train_size)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index,:]\n",
    "    mixed_y = lam * y + (1 - lam) * y[index]\n",
    "\n",
    "    # numpy array to pandas DataFrame\n",
    "    mixed_x = pd.DataFrame(mixed_x)\n",
    "    mixed_y = pd.Series(mixed_y)\n",
    "\n",
    "    return mixed_x, mixed_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train data and test data\n",
    "\n",
    "def load_data():\n",
    "    files = os.listdir(\"Data\")\n",
    "    train_file = \"blogData_train.csv\"\n",
    "    \n",
    "    train_data = pd.read_csv(\"./Data/{}\".format(train_file),header=None)\n",
    "    train_output = train_data[len(train_data.columns)-1]\n",
    "    train_num = train_data.shape[0]\n",
    "    del train_data[len(train_data.columns)-1]\n",
    "\n",
    "    files.remove(train_file)\n",
    "    file_list = files\n",
    "    test_data = pd.DataFrame()\n",
    "    for filename in file_list:\n",
    "        df = pd.read_csv(\"./Data/{}\".format(filename),header=None)\n",
    "        test_data = pd.concat([test_data, df], axis=0)\n",
    "    test_output = test_data[len(test_data.columns)-1]\n",
    "    del test_data[len(test_data.columns)-1]\n",
    "\n",
    "    data_X = pd.concat([train_data, test_data], axis=0)\n",
    "    data_Y = pd.concat([train_output, test_output], axis=0)\n",
    "\n",
    "    return data_X, data_Y, train_num\n",
    "\n",
    "\n",
    "def load_data_mixup():\n",
    "    files = os.listdir(\"Data\")\n",
    "    train_file = \"blogData_train.csv\"\n",
    "    \n",
    "    train_data = pd.read_csv(\"./Data/{}\".format(train_file),header=None)\n",
    "    train_output = train_data[len(train_data.columns)-1]\n",
    "    train_num = train_data.shape[0]\n",
    "    del train_data[len(train_data.columns)-1]\n",
    "    # mix up\n",
    "    train_data , train_output = mixup_data(train_data, train_output)\n",
    "\n",
    "    files.remove(train_file)\n",
    "    file_list = files\n",
    "    test_data = pd.DataFrame()\n",
    "    for filename in file_list:\n",
    "        df = pd.read_csv(\"./Data/{}\".format(filename),header=None)\n",
    "        test_data = pd.concat([test_data, df], axis=0)\n",
    "    test_output = test_data[len(test_data.columns)-1]\n",
    "    del test_data[len(test_data.columns)-1]\n",
    "\n",
    "    \n",
    "    data_X = pd.concat([train_data, test_data], axis=0)\n",
    "    data_Y = pd.concat([train_output, test_output], axis=0)\n",
    "\n",
    "    return data_X, data_Y, train_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(20, 15), squeeze=False)\n",
    "    \n",
    "    data_X, data_Y, train_num = load_data()\n",
    "    print(data_Y.shape, data_Y.shape)\n",
    "    print(train_num, data_X.shape[0])\n",
    "    \n",
    "    train_indices = [list(range(0, train_num))]\n",
    "    test_indices =  [list(range(train_num, data_X.shape[0]))]\n",
    "    custom_cv = zip(train_indices, test_indices)\n",
    "    \n",
    "    # rf = RandomForestRegressor(n_estimators=100, max_features=100)\n",
    "    linear_reg = LinearRegression()\n",
    "    plot_learning_curve(estimator=linear_reg, title=\"LinearRegression\", X=data_X, y=data_Y, axes=axes[:,0], cv=custom_cv, train_sizes=np.linspace(.1, 0.87, 70))\n",
    "    # plot_learning_curve(estimator=linear_reg, title=\"Random Forest\", X=data_X, y=data_Y, axes=axes[:,0], cv=custom_cv, train_sizes=np.linspace(.1, 0.87, 100))\n",
    "    # plt.show()\n",
    "\n",
    "    plt.ylim(-1, 1)\n",
    "    plt.savefig(\"./learning_curve(linear_reg).png\")\n",
    "    plt.close()\n",
    "\n",
    "def train_mixup():\n",
    "    print(\"Mix Up\")\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(20, 15), squeeze=False)\n",
    "    \n",
    "    data_X, data_Y, train_num = load_data_mixup()\n",
    "    print(data_X.shape, data_Y.shape)\n",
    "    print(train_num, data_X.shape[0])\n",
    "    train_indices = [list(range(0, train_num))]\n",
    "    test_indices =  [list(range(train_num, data_X.shape[0]))]\n",
    "    custom_cv = zip(train_indices, test_indices)\n",
    "    \n",
    "    # rf = RandomForestRegressor(n_estimators=100, max_features=100)\n",
    "    linear_reg = LinearRegression()\n",
    "    plot_learning_curve(estimator=linear_reg, title=\"LinearRegression\", X=data_X, y=data_Y, axes=axes[:,0], cv=custom_cv, train_sizes=np.linspace(.1, 0.87, 70))\n",
    "    # plot_learning_curve(estimator=linear_reg, title=\"Random Forest\", X=data_X, y=data_Y, axes=axes[:,0], cv=custom_cv, train_sizes=np.linspace(.1, 0.87, 100))\n",
    "    # plt.show()\n",
    "    plt.ylim(-1, 1)\n",
    "    plt.savefig(\"./learning_curve(linear_reg mix_up).png\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    train()\n",
    "    train_mixup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60021,) (60021,)\n",
      "52397 60021\n",
      "the shape of train_scores_mean (70,)\n",
      "[0.28253212 0.25854511 0.26203898 0.26460459 0.26453074 0.2656034\n",
      " 0.2668788  0.26340848 0.25411724 0.25468729 0.25566672 0.25364506\n",
      " 0.41012977 0.44538327 0.44532323 0.44146491 0.43534761 0.43234129\n",
      " 0.43125308 0.43037798 0.43047549 0.43017606 0.4263807  0.41989899\n",
      " 0.41562898 0.4141435  0.41286634 0.40962457 0.40894157 0.40306377\n",
      " 0.40225797 0.4027358  0.40310386 0.40353178 0.40385902 0.4036278\n",
      " 0.40369544 0.4022944  0.39798033 0.39380374 0.3932907  0.39275142\n",
      " 0.39204499 0.39194002 0.39077872 0.39059211 0.39022085 0.38923408\n",
      " 0.38817063 0.38739447 0.38746336 0.38750093 0.38640102 0.38617843\n",
      " 0.38621092 0.38609455 0.38601755 0.37629046 0.37650656 0.37606418\n",
      " 0.37453612 0.37438022 0.37430948 0.37445302 0.37359368 0.37111754\n",
      " 0.37054354 0.37006901 0.36926447 0.36853416]\n",
      "the shape of test_scores_mean (70,)\n",
      "[-1.66766019e+19 -1.25548796e+20 -1.92377582e+18 -2.07597809e+21\n",
      " -5.57300312e+18 -2.03837847e+20 -2.00869526e+20 -4.41302846e+19\n",
      " -5.31148759e+19 -1.68960238e+19 -2.41753604e+17 -1.67538941e+17\n",
      " -3.27694289e+18 -1.22982540e+17 -1.82736118e+16 -6.41667111e+14\n",
      " -2.06812018e+11 -3.95605832e+08 -2.50109573e+06 -5.28383532e+06\n",
      " -1.16880558e+04 -1.69677909e+15 -2.54569761e+15 -1.73352540e+04\n",
      " -1.05348130e+05 -5.91514022e+03 -9.21445754e+02 -5.16660130e+01\n",
      " -1.07281753e+15 -1.07750802e+03 -1.71080497e+02 -3.18624259e+03\n",
      " -2.79887798e+01 -1.46002481e+01 -8.11074557e+03 -8.93495390e+02\n",
      " -5.27709561e+01 -7.13014400e+10  5.39105716e-03 -1.26178346e+00\n",
      "  1.82024978e-02  1.29516912e-02 -1.30284524e+00 -4.36560793e+00\n",
      "  6.54662668e-02  8.52089577e-02  1.07848282e-01  3.13369893e-02\n",
      "  3.56891099e-03 -4.03761021e-02 -2.63469128e-02 -1.35846406e-02\n",
      "  2.88289215e-02  5.88148079e-02  6.52292354e-02  5.38311193e-02\n",
      "  2.04239815e-01  2.23711909e-01  2.44459976e-01  2.66105653e-01\n",
      "  2.61322375e-01  2.64160102e-01  2.66557282e-01  2.67756096e-01\n",
      "  2.63290140e-01  2.62942721e-01  2.61282654e-01  2.57466187e-01\n",
      "  2.58770687e-01  2.56916745e-01]\n",
      "Mix Up\n",
      "(60021, 280) (60021,)\n",
      "52397 60021\n",
      "the shape of train_scores_mean (70,)\n",
      "[0.29127039 0.26497469 0.26737214 0.26950594 0.2691048  0.27013336\n",
      " 0.27070565 0.26690477 0.25728028 0.25733788 0.25807037 0.25561315\n",
      " 0.4129558  0.44750437 0.44742469 0.44291323 0.43587953 0.43281745\n",
      " 0.43164309 0.43056456 0.43066269 0.43039619 0.42657177 0.42004955\n",
      " 0.41578749 0.41429093 0.41301255 0.40975669 0.4090775  0.40319787\n",
      " 0.4023813  0.40285665 0.40322487 0.40365193 0.40397886 0.40374906\n",
      " 0.40381753 0.40241396 0.39809054 0.39389888 0.39338285 0.39284419\n",
      " 0.39213123 0.39195977 0.39085862 0.39067295 0.39029781 0.38930876\n",
      " 0.38824669 0.38746856 0.38753689 0.38757499 0.38646344 0.38617236\n",
      " 0.38620449 0.38608726 0.38601023 0.37628303 0.37649654 0.37605491\n",
      " 0.37452716 0.37436974 0.37429848 0.37444171 0.37358247 0.37110914\n",
      " 0.37053587 0.37006187 0.36925768 0.36852815]\n",
      "the shape of test_scores_mean (70,)\n",
      "[-2.97903590e+03 -5.07810807e+03 -3.22821139e+03 -1.42564611e+03\n",
      " -1.38212833e+03 -1.57866567e+03 -2.35372377e+03 -2.23908761e+03\n",
      " -2.19078952e+03 -1.37357813e+03 -7.77126749e+02 -8.34660248e+02\n",
      " -4.34651407e+03 -7.43742551e+03 -5.54112058e+03 -1.04686858e+03\n",
      " -1.09596513e+03 -3.46454375e+02 -3.41642632e+02 -4.17952266e+01\n",
      " -5.09652788e+01 -5.06915334e+01 -4.76845857e+01 -8.17036635e+01\n",
      " -9.41204175e+01 -1.00668730e+02 -1.00815958e+02 -9.46082664e+01\n",
      " -8.47324511e+01 -8.12452271e+01 -4.05636187e+00 -4.14639751e+00\n",
      " -4.22886121e+00 -4.29399430e+00 -4.35828421e+00 -5.09469205e+00\n",
      " -5.28141425e+00 -3.84365707e+00 -3.53148098e+00 -2.97102511e+00\n",
      " -2.78533064e+00 -3.03487271e+00 -2.68199270e+00 -2.63706591e+00\n",
      " -1.21644014e+00 -1.18617006e+00 -1.12234936e+00  3.52885611e-02\n",
      "  1.15010634e-02 -3.79972412e-02 -2.40852804e-02 -9.88449587e-03\n",
      "  3.19232616e-02  6.29081935e-02  6.91988693e-02  5.78077649e-02\n",
      "  2.05299145e-01  2.24509417e-01  2.51434564e-01  2.64660854e-01\n",
      "  2.60777844e-01  2.63691612e-01  2.66109612e-01  2.67313067e-01\n",
      "  2.62834034e-01  2.62541966e-01  2.60882658e-01  2.57391723e-01\n",
      "  2.58355452e-01  2.56535997e-01]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ]
}